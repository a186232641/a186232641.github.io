<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>mysql实战45讲读书笔记</title>
      <link href="/2024/05/24/mysql%E5%AE%9E%E6%88%9845%E8%AE%B2%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/05/24/mysql%E5%AE%9E%E6%88%9845%E8%AE%B2%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="1-一条SQL查询语句是如何执行的？"><a href="#1-一条SQL查询语句是如何执行的？" class="headerlink" title="1. 一条SQL查询语句是如何执行的？"></a>1. 一条SQL查询语句是如何执行的？</h2><p><img src="/../images/0d2070e8f84c4801adbfa03bda1f98d9.png" alt="img"></p><ol><li><p>Server 层</p><ol><li>Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等）</li></ol></li><li><p>存储引擎层</p><ol><li>存储引擎层负责数据的存储和提取</li><li>架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。</li><li>执行create table建表的时候，如果不指定引擎类型，默认使用的就是InnoDB</li><li>你也可以通过指定存储引擎的类型来选择别的引擎，比如在create table语句中使用engine&#x3D;memory, 来指定使用内存引擎创建表</li></ol></li></ol><h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h$ip -P$port -u$user -p</span><br></pre></td></tr></table></figure><ul><li>如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。</li><li>如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。</li></ul><p>一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show processlist #查看全部连接</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wait_timeout #控制客户端无动静后最长的连接时间</span><br><span class="line">SHOW VARIABLES LIKE &#x27;wait_timeout&#x27;;</span><br><span class="line">SET GLOBAL wait_timeout = &lt;desired_timeout_in_seconds&gt;;</span><br></pre></td></tr></table></figure><p>连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。</p><ol><li>长连接<ol><li>长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接</li></ol></li><li>短连接<ol><li>短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。</li></ol></li></ol><p>使用长连接后存在的问题</p><ol><li>内存占用太大被系统杀掉，mysql表现异常重启</li></ol><p>如何解决</p><ol><li>定期断开长连接。</li><li>MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li></ol><h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>缓存以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。</p><p><strong>缓存失效非常快</strong></p><h3 id="3-分析器"><a href="#3-分析器" class="headerlink" title="3. 分析器"></a>3. 分析器</h3><ol><li><p>词法分析</p><ol><li>你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么</li><li>如识别”select”这个关键字</li></ol></li><li><p>语法分析</p><p>词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法</p></li></ol><h3 id="4-优化器"><a href="#4-优化器" class="headerlink" title="4. 优化器"></a>4. 优化器</h3><p>选择走哪个索引</p><h3 id="5-执行器"><a href="#5-执行器" class="headerlink" title="5. 执行器"></a>5. 执行器</h3><ol><li>检查执行权限<ol><li>无<ol><li>返回没有权限错误</li></ol></li><li>有<ol><li>调用存储引擎层接口</li></ol></li></ol></li></ol><h2 id="2-日志系统：一条SQL更新语句是如何执行的？"><a href="#2-日志系统：一条SQL更新语句是如何执行的？" class="headerlink" title="2. 日志系统：一条SQL更新语句是如何执行的？"></a>2. 日志系统：一条SQL更新语句是如何执行的？</h2><ol><li>更新语句会把表T上所有缓存结果都清空</li><li>分析器会通过词法和语法解析知道这是一条更新语句</li><li>优化器决定要使用ID这个索引。</li><li>执行器负责具体执行，找到这一行，然后更新</li></ol><h4 id="redo-log-重做日志"><a href="#redo-log-重做日志" class="headerlink" title="redo log(重做日志)"></a>redo log(重做日志)</h4><p>redo log是<strong>InnoDB引擎特有的日志</strong></p><p>Redo log 比作粉板 mysql比作账本</p><p>粉板和账本配合的整个过程，其实就是MySQL里经常说到的WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。</p><p>具体流程：</p><p>InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。</p><p>InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么这块“粉板”总共就可以记录4GB的操作。</p><p>循环写</p><p>write pos是当前记录的位置一边写一边后移、checkpoint是当前要擦除的位置也是往后推移并且循环的，擦除记录前要把记录更新到数据文件</p><p>write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。</p><p>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为<strong>crash-safe</strong></p><p><img src="/../images/16a7950217b3f0f4ed02db5db59562a7.png" alt="img"></p><h4 id="binlog-归档日志"><a href="#binlog-归档日志" class="headerlink" title="binlog(归档日志)"></a>binlog(归档日志)</h4><ol><li><p>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</p></li><li><p><strong>redo log</strong>是物理日志，记录的是“<strong>在某个数据页上做了什么修改</strong>”；<strong>binlog</strong>是逻辑日志，记录的是这个语句的原始逻辑，<strong>比如“给ID&#x3D;2这一行的c字段加1</strong> ”。</p></li><li><p>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p></li></ol><p>update语句的内部流程</p><p><img src="/../images/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png" alt="img"></p><h4 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h4><p> Redo Log 进入 Prepared 状态时，表示该事务的 Redo Log 已经被<strong>持久化到磁盘</strong>，但还没有提交。</p><p>通过将 binlog 持久化到磁盘</p><p>为什么需要两阶段提交？</p><p>redo log和binlog是两个<strong>独立的逻辑</strong>，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p><ol><li><p><strong>先写redo log后写binlog</strong></p><p>假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。<br>但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的<strong>binlog里面就没有这条语句</strong>。</p><p>如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。</p></li><li><p><strong>先写binlog后写redo log</strong></p></li></ol><p>​如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。</p><p>sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my.cnf</span><br><span class="line">innodb_flush_log_at_trx_commit = 1</span><br><span class="line">sync_binlog = 1</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="3-事务隔离：为什么你改了我还看不见？"><a href="#3-事务隔离：为什么你改了我还看不见？" class="headerlink" title="3. 事务隔离：为什么你改了我还看不见？"></a>3. 事务隔离：为什么你改了我还看不见？</h2><h1 id="隔离性与隔离级别"><a href="#隔离性与隔离级别" class="headerlink" title="隔离性与隔离级别"></a>隔离性与隔离级别</h1><p>ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）</p><ol><li>脏读（dirty read）</li><li>不可重复读（non-repeatable read）</li><li>幻读（phantom read）</li></ol><p>SQL标准的事务隔离级别包括：</p><ol><li><p>读未提交（read uncommitted）</p><p>一个事务还没提交时，它做的变更就能被别的事务看到</p></li><li><p>读提交（read committed）</p><p>一个事务提交之后，它做的变更才会被其他事务看到。</p></li><li><p>可重复读（repeatable read）</p><p>一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的</p></li><li><p>串行化（serializable ）</p><p>对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create table T(c int) engine=InnoDB;</span><br><span class="line">insert into T(c) values(1);</span><br></pre></td></tr></table></figure></li></ol><p><img src="/../images/7dea45932a6b722eb069d2264d0066f8.png" alt="img"></p><ol><li><p>读未提交</p><p>V1、V2、V3 都是2</p></li><li><p>读提交</p><p>V1&#x3D;1、V2、V3 都是2</p></li><li><p>可重复读</p><p>V1 v2都是1、 v3是2</p></li><li><p>串行化</p><p>事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。</p><p> V1、V2值是1，V3的值是2。</p></li></ol><h1 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h1><p><img src="/../images/d9c313809e5ac148fc39feff532f0fee.png" alt="img"></p><p>假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。</p><p>这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。</p><h4 id="什么时候删除回滚日志"><a href="#什么时候删除回滚日志" class="headerlink" title="什么时候删除回滚日志"></a>什么时候删除回滚日志</h4><p>在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。</p><p>什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。</p><h4 id="为什么建议你尽量不要使用长事务"><a href="#为什么建议你尽量不要使用长事务" class="headerlink" title="为什么建议你尽量不要使用长事务"></a>为什么建议你尽量不要使用长事务</h4><p>这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p><h4 id="如何避免长事务"><a href="#如何避免长事务" class="headerlink" title="如何避免长事务"></a>如何避免长事务</h4><ol><li>确认是否使用了set autocommit&#x3D;0。确认是否使用了set autocommit&#x3D;0。这个确认工作可以在测试环境中开展，把MySQL的general_log开起来，然后随便跑一个业务逻辑，通过general_log的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成1。</li><li>只读事务可以去掉</li><li>业务连接数据库的时候，根据业务本身的预估，通过SET MAX_EXECUTION_TIME命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。</li><li>监控 information_schema.Innodb_trx表，设置长事务阈值，超过就报警&#x2F;或者kill；</li><li>把innodb_undo_tablespaces设置成2（或更大的值）。</li></ol><h4 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h4><ol><li>显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。</li><li>set autocommit&#x3D;0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">commit work and chain #提交事务并自动启动下一个事务</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60#查找持续时间超过60s的事务</span><br></pre></td></tr></table></figure><h2 id="4-深入浅出索引（上）"><a href="#4-深入浅出索引（上）" class="headerlink" title="4. 深入浅出索引（上）"></a>4. 深入浅出索引（上）</h2><p>给表添加索引</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_username ON users (username);</span><br><span class="line">CREATE INDEX idx_username_email ON users (username, email);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>创建时添加索引</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">列定义后面使用 INDEX 或 KEY 关键字来实现。</span><br><span class="line">CREATE TABLE users (</span><br><span class="line">    id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    username VARCHAR(255),</span><br><span class="line">    email VARCHAR(255),</span><br><span class="line">    INDEX idx_username (username),</span><br><span class="line">    INDEX idx_email (email)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">CREATE TABLE users (</span><br><span class="line">    id INT AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">    username VARCHAR(255),</span><br><span class="line">    email VARCHAR(255),</span><br><span class="line">    KEY idx_username (username),</span><br><span class="line">    KEY idx_email (email)</span><br><span class="line">);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如何删除索引</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DROP INDEX idx_username ON users;</span><br><span class="line">想删除 users 表上的 PRIMARY KEY 索引</span><br><span class="line">ALTER TABLE users DROP PRIMARY KEY;</span><br><span class="line">如果要删除的索引是唯一索引</span><br><span class="line">ALTER TABLE table_name DROP INDEX index_name;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create table T(</span><br><span class="line">id int primary key, </span><br><span class="line">k int not null, </span><br><span class="line">name varchar(16),</span><br><span class="line">index (k))engine=InnoDB;</span><br></pre></td></tr></table></figure><p><img src="/../images/dcda101051f28502bd5c4402b292e38d.png" alt="img"></p><p>索引类型</p><ol><li><p>主键索引 ｜ 聚簇索引</p><p>主键索引的叶子节点存的是整行数据</p></li><li><p>非主键索引 ｜ 二级索引</p><p>非主键索引的叶子节点内容是主键的值</p></li></ol><p>查询非主键索引会查到主键id 然后从主键树中查找 id并返回数据，叫做回表</p><h4 id="基于主键索引和普通索引的查询有什么区别？"><a href="#基于主键索引和普通索引的查询有什么区别？" class="headerlink" title="基于主键索引和普通索引的查询有什么区别？"></a>基于主键索引和普通索引的查询有什么区别？</h4><ul><li>如果语句是select * from T where ID&#x3D;500，即主键查询方式，则只需要搜索ID这棵B+树；</li><li>如果语句是select * from T where k&#x3D;5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为<strong>回表</strong>。</li></ul><h4 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h4><p>如果插入id为400 但R5所在的页满，会导致页分裂</p><p>当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。</p><p>解决办法</p><ol><li>使用自增主键</li></ol><p>​自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。插入新记录的时候可以不指定ID的值，系统会获取当前ID最大值加1作为下一条记录的ID值。</p><p><strong>主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong></p><h2 id="5-深入浅出索引（下）"><a href="#5-深入浅出索引（下）" class="headerlink" title="5. 深入浅出索引（下）"></a>5. 深入浅出索引（下）</h2><p><img src="/../images/dcda101051f28502bd5c4402b292e38d-20240525220555522.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from T where k between 3 and 5</span><br></pre></td></tr></table></figure><ol><li>在k索引树上找到k&#x3D;3的记录，取得 ID &#x3D; 300；</li><li>再到ID索引树查到ID&#x3D;300对应的R3；</li><li>在k索引树取下一个值k&#x3D;5，取得ID&#x3D;500；</li><li>再回到ID索引树查到ID&#x3D;500对应的R4；</li><li>在k索引树取下一个值k&#x3D;6，不满足条件，循环结束。</li></ol><p><strong>回到主键索引树搜索的过程，我们称为回表</strong></p><h4 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h4><p>select ID from T where k between 3 and 5，这时只需要<strong>查ID的值</strong>，而<strong>ID的值已经在k索引树</strong>上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引。</p><p><strong>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</strong></p><h4 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h4><p><strong>B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。</strong></p><p><img src="/../images/89f74c631110cfbc83298ef27dcd6370.jpg" alt="img"></p><p>当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到ID4，然后向后遍历得到所有需要的结果。</p><p>你要查的是所有名字第一个字是“张”的人，你的SQL语句的条件是”where name like ‘张%’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是ID3，然后向后遍历，直到不满足条件为止。</p><p>不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。</p><h4 id="在建立联合索引的时候，如何安排索引内的字段顺序"><a href="#在建立联合索引的时候，如何安排索引内的字段顺序" class="headerlink" title="在建立联合索引的时候，如何安排索引内的字段顺序"></a><strong>在建立联合索引的时候，如何安排索引内的字段顺序</strong></h4><p>当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了。因此，<strong>第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</strong></p><h4 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h4><p>在索引遍历过程中，对索引中包含的字段先做判断</p><p><img src="/../images/b32aa8b1f75611e0759e52f5915539ac.jpg" alt="img"></p><p>索引下推的执行流程</p><p><img src="/../images/76e385f3df5a694cc4238c7b65acfe1b.jpg" alt="img"></p><h2 id="6-全局锁和表锁-：给表加个字段怎么有这么多阻碍？"><a href="#6-全局锁和表锁-：给表加个字段怎么有这么多阻碍？" class="headerlink" title="6. 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？"></a>6. 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？</h2><h4 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h4><figure class="highlight plaintext"><figcaption><span>tables with read lock (FTWRL)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。</span><br></pre></td></tr></table></figure><p>使用场景</p><p>全局锁的典型使用场景是，做全库逻辑备份</p><p>缺点</p><p>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆</p><p>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。</p><p>官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。</p><p>single-transaction方法只适用于所有的表使用事务引擎的库。**如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL方法。这往往是DBA要求业务开发人员使用InnoDB替代MyISAM的原因之一</p><p><strong>既然要全库只读，为什么不使用set global readonly&#x3D;true的方式呢</strong>？确实readonly方式也可以让全库进入只读状态，但我还是会建议你用FTWRL方式，主要有两个原因：</p><ul><li>一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。</li><li>二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。</li></ul><h4 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h4><ol><li><p>表锁</p><ol><li>表锁的语法是 lock tables … read&#x2F;write、unlock tables主动释放锁也可以在客户端断开的时候自动释放。lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</li><li></li></ol></li><li><p>元数据锁(meta data lock，MDL)</p><p>MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，<strong>保证读写的正确性</strong>。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个<strong>表结构做变更</strong>，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。</p><p>在MySQL 5.5版本中引入了MDL，当对一个表做<strong>增删改查操作的时候，加MDL读锁</strong>；当要对<strong>表做结构变更操作</strong>的时候，<strong>加MDL写锁</strong>。</p></li></ol><ul><li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li><li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</li></ul><p><img src="/../images/7cf6a3bf90d72d1f0fc156ececdfb0ce.jpg" alt="img"></p><ol><li>session A先启动，这时候会对表t加一个MDL读锁。由于session B需要的也是MDL读锁，因此可以正常执行。</li><li>session C会被blocked，是因为session A的MDL读锁还没有释放，而session C需要MDL写锁，因此只能被阻塞。</li><li>有session C自己被阻塞还没什么关系，但是之后所有要在表t上新申请MDL读锁的请求也会被session C阻塞。</li><li>，事务中的MDL锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。</li></ol><h4 id="如何安全地给小表加字段？"><a href="#如何安全地给小表加字段？" class="headerlink" title="如何安全地给小表加字段？"></a><strong>如何安全地给小表加字段？</strong></h4><ol><li><p>解决长事务</p></li><li><p>MySQL的information_schema 库的 innodb_trx 表你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。</p><ol><li><pre><code>use information_schemaselect * from innodb_trx<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">      </span><br><span class="line"></span><br><span class="line">3. 你要变更的表是一个热点表，上面的请求很频繁，而你不得不加个字段，你该怎么做呢，alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好</span><br><span class="line"></span><br><span class="line">4. ```</span><br><span class="line">   ALTER TABLE tbl_name NOWAIT add column ...</span><br><span class="line">   ALTER TABLE tbl_name WAIT N add column ... </span><br></pre></td></tr></table></figure></code></pre></li></ol></li></ol><h2 id="08-事务到底是隔离的还是不隔离的？"><a href="#08-事务到底是隔离的还是不隔离的？" class="headerlink" title="08  事务到底是隔离的还是不隔离的？"></a>08  事务到底是隔离的还是不隔离的？</h2><p>一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？</p><p><img src="/../images/823acf76e53c0bdba7beab45e72e90d6.png" alt="img"></p><p>begin&#x2F;start transaction 命令<strong>并不是一个事务的起点</strong>，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。如果你想要<strong>马上启动一个事务</strong>，可以使用start transaction with consistent snapshot 这个命令。</p><p>这里设置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET autocommit = 1;  -- 开启自动提交</span><br><span class="line">SET autocommit = 0;  -- 关闭自动提交</span><br></pre></td></tr></table></figure><p>在MySQL里，有两个“视图”的概念：</p><ul><li>一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view … ，而它的查询方法与表一样。</li><li>另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。</li></ul><h4 id="“快照”在MVCC里是怎么工作的？"><a href="#“快照”在MVCC里是怎么工作的？" class="headerlink" title="“快照”在MVCC里是怎么工作的？"></a>“快照”在MVCC里是怎么工作的？</h4><p>InnoDB里面每个事务有一个唯一的事务ID，叫作<strong>transaction id</strong>。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。</p><p>每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id</p><p>数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id。</p><p><img src="/../images/68d08d277a6f7926a41cc5541d3dfced.png" alt="img"></p><p>虚线框里是同一行数据的4个版本，当前最新版本是V4，k的值是22，它是被transaction id 为25的事务更新的，因此它的row trx_id也是25。</p><p>语句更新会生成undo log（回滚日志）吗？那么，<strong>undo log在哪呢？</strong></p><p>图2中的三个虚线箭头，就是<strong>undo log；而V1、V2、V3并不是物理上真实存在的</strong>，而是每次需要的时候根据当前版本和undo log计算出来的。比如，需要V2的时候，就是通过V4依次执行U3、U2算出来。</p><p> InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。</p><p><img src="/../images/882114aaf55861832b4270d44507695e.png" alt="img"></p><p>对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能：</p><ol><li>如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li><li>如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</li><li>如果落在黄色部分，那就包括两种情况<br>a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见；<br>b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。</li></ol><p><strong>InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</strong></p><p><img src="/../images/9416c310e406519b7460437cb0c5c149.png" alt="img"></p><p>从图中可以看到，**第一个有效更新是事务C，把数据从(1,1)改成了(1,2)**。这时候，这个数据的最新版本的row trx_id是102，而90这个版本已经成为了历史版本。</p><p>第二个有效更新是事务B**，把数据从(1,2)改成了(1,3)**。这时候，这个数据的最新版本（即row trx_id）是101，而102又成为了历史版本。</p><p>你可能注意到了，在事务A查询的时候，其实事务B还没有提交，但是它生成的(1,3)这个版本已经变成当前版本了。但这个版本对事务A必须是不可见的，否则就变成脏读了。</p><p>好，现在事务A要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务A查询语句的读数据流程是这样的：</p><ul><li>找到(1,3)的时候，<strong>判断出row trx_id&#x3D;101</strong>，比高水位大，处于红色区域，不可见；</li><li>接着，找到上一个历史版本，一看row trx_id&#x3D;102，比高水位大，处于红色区域，不可见；</li><li>再往前找，终于找到了（1,1)，它的row trx_id&#x3D;90，比低水位小，处于绿色区域，可见。</li></ul><p>这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为<strong>一致性读</strong>。</p><h3 id="更新逻辑"><a href="#更新逻辑" class="headerlink" title="更新逻辑"></a>更新逻辑</h3><p><strong>事务B的update语句，如果按照一致性读，好像结果不对哦？</strong></p><img src="/2024/05/24/mysql%E5%AE%9E%E6%88%9845%E8%AE%B2%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/images/86ad7e8abe7bf16505b97718d8ac149f.png" alt="img" style="zoom:75%;"><p>如果事务B在更新之前查询一次数据，这个查询返回的k的值确实是1。</p><p>但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务C的更新就丢失了。因此，事<strong>务B此时的set k&#x3D;k+1是在（1,2）的基础上进行的操</strong>作。</p><p><strong>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。</strong></p><p>当前读。其实，除了update语句外，<strong>select语句如果加锁</strong>，也是当前读。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select k from t where id=1 lock in share mode;</span><br><span class="line">select k from t where id=1 for update;</span><br></pre></td></tr></table></figure><p><img src="/../images/cda2a0d7decb61e59dddc83ac51efb6e.png" alt="img"></p><p>事务C’的不同是，更新后并没有马上提交，在它提交前，事务B的更新语句先发起了。前面说过了，虽然事务C’还没提交，但是(1,2)这个版本也已经生成了，并且是当前的最新版本。那么，事务B的更新语句会怎么处理呢？</p><p>事务C’没提交，也就是说**(1,2)这个版本上的写锁还没释放<strong>。而事务B是</strong>当前读<strong>，必须</strong>要读最新版本，而且必须加锁<strong>，因此就被锁住了，必须等到</strong>事务C’释放这个锁**，才能继续它的当前读。</p><p><img src="/../images/540967ea905e8b63630e496786d84c92.png" alt="img"></p><h4 id="事务的可重复读的能力是怎么实现的？"><a href="#事务的可重复读的能力是怎么实现的？" class="headerlink" title="事务的可重复读的能力是怎么实现的？"></a>事务的可重复读的能力是怎么实现的？</h4><ul><li>在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；</li><li>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。</li></ul><p>设置数据库的隔离级别</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;</span><br><span class="line">SET TRANSACTION ISOLATION LEVEL READ COMMITTED;</span><br><span class="line">SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;</span><br><span class="line">SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;</span><br></pre></td></tr></table></figure><h3 id="9-普通索引和唯一索引，应该怎么选择？"><a href="#9-普通索引和唯一索引，应该怎么选择？" class="headerlink" title="9. 普通索引和唯一索引，应该怎么选择？"></a>9. 普通索引和唯一索引，应该怎么选择？</h3><p><img src="/../images/1ed9536031d6698570ea175a7b7f9a46.png" alt="img"></p><h3 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a>查询过程</h3><p><strong>InnoDB的数据是按数据页为单位来读写的</strong>。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB。</p><p>查找到索引所在的数据页，然后一条条比对</p><h3 id="更新过程"><a href="#更新过程" class="headerlink" title="更新过程"></a>更新过程</h3><h5 id="change-buffer"><a href="#change-buffer" class="headerlink" title="change buffer"></a>change buffer</h5><p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个<strong>数据页还没有在内存中的话</strong>，在不影响数据一致性的前提下，InooDB会将这些<strong>更新操作缓存在change buffer</strong>中，这样就不需要从磁盘中读入这个数据页了。</p><p>在下次查询需要访问这个数据页的时候，将数据页读入内存，然后<strong>执行change buffer中与这个页有关的操作</strong>。通过这种方式就能保证这个数据逻辑的正确性。</p><p>虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，<strong>change buffer在内存中有拷贝，也会被写入到磁盘上。</strong></p><p>将change buffer中的操作应用到原数据页，得到最新结果的过程称为<strong>merge</strong>。</p><h5 id="什么条件下可以使用change-buffer呢？"><a href="#什么条件下可以使用change-buffer呢？" class="headerlink" title="什么条件下可以使用change buffer呢？"></a>什么条件下可以使用change buffer呢？</h5><p>对于<strong>唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束</strong>。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k&#x3D;4的记录，而这必须要将数据页读入内存才能判断。如果<strong>都已经读入到内存</strong>了，那<strong>直接更新内存会更快，就没必要使用change buffer</strong>了。</p><p>因此，唯一索引的更新就不能使用change buffer，实际上也只有<strong>普通索引可以使用</strong>。</p><p>change buffer用的是buffer pool里的内存，因此不能无限增大。change buffer的大小，可以通过参数<strong>innodb_change_buffer_max_size</strong>来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。</p><h4 id="change-buffer的使用场景"><a href="#change-buffer的使用场景" class="headerlink" title="change buffer的使用场景"></a>change buffer的使用场景</h4><p>对于<strong>写多读少</strong>的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。</p><p>假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将<strong>更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程</strong>。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，<strong>change buffer反而起到了副作用</strong>。</p><h4 id="索引选择和实践"><a href="#索引选择和实践" class="headerlink" title="索引选择和实践"></a>索引选择和实践</h4><p>普通索引和唯一索引应该怎么选择。其实，这两类索引在<strong>查询能力上是没差别的</strong>，主要考虑的是对<strong>更新性能的影响</strong>。所以，我建议你尽量选择普通索引。</p><p>如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在其他情况下，change buffer都能提升更新性能。</p><p>普通索引和change buffer的配合使用，对于数据量大的表的更新优化还是很明显的。</p><h4 id="change-buffer-和-redo-log"><a href="#change-buffer-和-redo-log" class="headerlink" title="change buffer 和 redo log"></a>change buffer 和 redo log</h4><p><img src="/../images/980a2b786f0ea7adabef2e64fb4c4ca3.png" alt="img"></p><p>分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。</p><p>这条更新语句做了如下的操作（按照图中的数字顺序）：</p><ol><li>Page 1在内存中，直接更新内存；</li><li>Page 2没有在内存中，就在内存的change buffer区域，记录下“我要往Page 2插入一行”这个信息</li><li>将上述两个动作记入redo log中（图中3和4）。</li></ol><p>做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。</p><p>同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。</p><p><strong>redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。</strong></p><h3 id="10-MySQL为什么有时候会选错索引？"><a href="#10-MySQL为什么有时候会选错索引？" class="headerlink" title="10.MySQL为什么有时候会选错索引？"></a>10.MySQL为什么有时候会选错索引？</h3><h4 id="优化器的逻辑"><a href="#优化器的逻辑" class="headerlink" title="优化器的逻辑"></a>优化器的逻辑</h4><p>优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。</p><p>当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。</p><p>我们这个简单的查询语句并没有涉及到临时表和排序，所以MySQL选错索引肯定是在<strong>判断扫描行数</strong>的时候出问题了。</p><h4 id="扫描行数是怎么判断的？"><a href="#扫描行数是怎么判断的？" class="headerlink" title="扫描行数是怎么判断的？"></a><strong>扫描行数是怎么判断的？</strong></h4><p>MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。</p><p>显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“<strong>基数</strong>”（cardinality）。</p><h5 id="MySQL是怎样得到索引的基数的呢？"><a href="#MySQL是怎样得到索引的基数的呢？" class="headerlink" title="MySQL是怎样得到索引的基数的呢？"></a>MySQL是怎样得到索引的基数的呢？</h5><p>nnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。</p><p><img src="/../images/e2bc5f120858391d4accff05573e1289.png" alt="img"></p><p>Q1的结果还是符合预期的，rows的值是104620；但是Q2的rows值是37116，偏差就大了。而图1中我们用explain命令看到的rows是只有10001行，是这个偏差误导了优化器的判断。</p><p>到这里，可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描37000行的执行计划不用，却选择了扫描行数是100000的执行计划呢？</p><p>这是因为，如果使用索引a，每次从索引a上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。</p><p>优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">analyze table t 可以用来重新统计索引信息</span><br></pre></td></tr></table></figure><h4 id="索引选择异常和处理"><a href="#索引选择异常和处理" class="headerlink" title="索引选择异常和处理"></a>索引选择异常和处理</h4><p>其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的SQL语句，执行速度却比你预期的慢很多，你应该怎么办呢？</p><p>一种方法是，像我们第一个例子一样，<strong>采用force index强行选择一个索引</strong>。**MySQL会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果force index指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。</p><p><img src="/../images/9582401a6bed6cb8fd803c9555750b54.png" alt="img"></p><p>既然优化器放弃了使用索引a，说明a还不够合适，所以<strong>第二种方法就是，我们可以考虑修改语句，引导MySQL使用我们期望的索引。</strong>比如，在这个例子里，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。</p><p><img src="/../images/14cd598e52a2b72dd334a42603e5b894.png" alt="img"></p><p><strong>第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</strong></p><h3 id="11-怎么给字符串字段加索"><a href="#11-怎么给字符串字段加索" class="headerlink" title="11.怎么给字符串字段加索"></a>11.怎么给字符串字段加索</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter table SUser add index index1(email);</span><br><span class="line">alter table SUser add index index2(email(6));</span><br></pre></td></tr></table></figure><img src="/2024/05/24/mysql%E5%AE%9E%E6%88%9845%E8%AE%B2%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/images/d31da662bee595991862c439a5567eb7.jpg" alt="img" style="zoom:50%;"><img src="/2024/05/24/mysql%E5%AE%9E%E6%88%9845%E8%AE%B2%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/images/134583875561de914991fc2e192cf842.jpg" alt="img" style="zoom:50%;"><p>使用第一种查询到直接返回</p><p>第二种查询到需要再查ID 然后才返回</p><p>首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(distinct email) as L from SUser;</span><br></pre></td></tr></table></figure><ol><li>直接创建完整索引，这样可能比较占用空间；</li><li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；</li><li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；</li><li>创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。</li></ol><h3 id="12-为什么我的MySQL会“抖”一下？"><a href="#12-为什么我的MySQL会“抖”一下？" class="headerlink" title="12.为什么我的MySQL会“抖”一下？"></a>12.为什么我的MySQL会“抖”一下？</h3><p><strong>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”</strong>。</p><p><img src="/../images/349cfab9e4f5d2a75e07b2132a301fda.jpeg" alt="img"></p><p>掌柜在什么情况下会把粉板上的赊账记录改到账本上？</p><ul><li><p>第一种场景是，粉板满了，记不下了。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。当然在擦掉之前，他必须先将正确的账目记录到账本中才行。这个场景，对应的就是InnoDB的redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。我在第二讲画了一个redo log的示意图，这里我改成环形，便于大家理解。</p><p><img src="/../images/a25bdbbfc2cfc5d5e20690547fe7f2e5-20240601171530918.jpg" alt="img"></p></li><li><p>第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。</p><ul><li>“内存不够用了，要先将脏页写到磁盘”，<strong>InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：</strong><ul><li>第一种是，还没有使用的；</li><li>第二种是，使用了并且是干净页；</li><li>第三种是，使用了并且是脏页。</li><li>当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。</li><li>这种场景，对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。<br>你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用不就行了？这里其实是从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：</li></ul></li></ul></li><li><p>一种是内存里存在，内存里就肯定是正确的结果，直接返回；</p></li><li><p>另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。<br>这样的效率最高。</p></li><li><p>第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。</p></li><li><p>第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。<br>这种场景，对应的就是MySQL正常关闭的情况。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。</p></li></ul><h4 id="InnoDB刷脏页的控制策略"><a href="#InnoDB刷脏页的控制策略" class="headerlink" title="InnoDB刷脏页的控制策略"></a>InnoDB刷脏页的控制策略</h4><p>首先，你要正确地告诉InnoDB所在主机的IO能力，这样InnoDB才能知道需要全力刷脏页的时候，可以刷多快。</p><p>这就要用到innodb_io_capacity这个参数了，它会告诉InnoDB你的磁盘能力。这个值我建议你设置成磁盘的IOPS。磁盘的IOPS可以通过fio这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：</p><h5 id="如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？"><a href="#如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？" class="headerlink" title="如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？"></a><strong>如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？</strong></h5><p>一个是脏页比例，一个是redo log写盘速度。数innodb_max_dirty_pages_pct是脏页比例上限，默认值是75%</p><p>InnoDB会根据当前的脏页比例（假设为M），算出一个范围在0到100之间的数字，计算这个数字的伪代码类似这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">F1(M)</span><br><span class="line">&#123;</span><br><span class="line">  if M&gt;=innodb_max_dirty_pages_pct then</span><br><span class="line">      return 100;</span><br><span class="line">  return 100*M/innodb_max_dirty_pages_pct;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>InnoDB每次写入的日志都有一个序号，当前写入的序号跟checkpoint对应的序号之间的差值，我们假设为N。InnoDB会根据这个N算出一个范围在0到100之间的数字，这个计算公式可以记为F2(N)。F2(N)算法比较复杂，你只要知道N越大，算出来的值越大就好了。</p><p><strong>根据上述算得的F1(M)和F2(N)两个值，取其中较大的值记为R，之后引擎就可以按照innodb_io_capacity定义的能力乘以R%来控制刷脏页的速度。</strong></p><p><img src="https://static001.geekbang.org/resource/image/cc/74/cc44c1d080141aa50df6a91067475374.png" alt="img"></p><p>你就要合理地设置innodb_io_capacity的值，并且**平时要多关注脏页比例，不要让它经常接近75%**。</p><p>一旦一个查询请求需要在执行过程中<strong>先flush掉一个脏页时</strong>，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：在<strong>准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。</strong></p><p>在InnoDB中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为1的时候会有上述的“连坐”机制，值为0时表示不找邻居，自己刷自己的。</p><p>在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。</p><h3 id="13-为什么表数据删掉一半，表文件大小不变"><a href="#13-为什么表数据删掉一半，表文件大小不变" class="headerlink" title="13 .为什么表数据删掉一半，表文件大小不变?"></a>13 .为什么表数据删掉一半，表文件大小不变?</h3><h4 id="参数innodb-file-per-table"><a href="#参数innodb-file-per-table" class="headerlink" title="参数innodb_file_per_table"></a>参数innodb_file_per_table</h4><p>表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table控制的：</p><p>​这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；</p><p>​这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。</p><p><strong>将innodb_file_per_table设置为ON，是推荐做法，我们接下来的讨论都是基于这个设置展开的。</strong></p><p>我们在删除整个表的时候，可以使用<strong>drop table命令回收表空间</strong>。但是，我们遇到的更多的删除<strong>数据的场景是删除某些行</strong>，这时就遇到了我们文章开头的问题：表中的数据被删除了，但是表空间却没有被回收。</p><h4 id="数据删除流程"><a href="#数据删除流程" class="headerlink" title="数据删除流程"></a>数据删除流程</h4><p><img src="/../images/f0b1e4ac610bcb5c5922d0b18563f3c8.png" alt="img"></p><p>们要删掉R4这个记录，InnoDB引擎只会把R4这个记录标记为删除。如果之后要再插入一个ID在300和600之间的记录时，<strong>可能会复用这个位置</strong>。但是，磁盘文件的大小并不会缩小。</p><p>现在，你已经知道了InnoDB的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，会怎么样？</p><p>答案是，整个数据页就可以被复用了。</p><p><strong>数据页的复用跟记录的复用是不同的。</strong></p><p>记录的复用，只限于符合范围条件的数据。</p><p>R4这条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。但如果插入的是一个ID是800的行，就不能复用这个位置了。</p><p>而当整个页从B+树里面摘掉以后，可以复用到任何位置。以图1为例，如果将数据页page A上的所有记录删除以后，page A会被标记为可复用。这时候如果要插入一条ID&#x3D;50的记录需要使用新页的时候，page A是可以被复用的。</p><p>如果<strong>相邻的两个数据页利用率都很小</strong>，系统就会把这两个页上的数据合到其中一个页上，<strong>另外一个数据页就被标记为可复用</strong>。</p><p>delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。</p><p>实际上，<strong>不止是删除数据会造成空洞，插入数据也会。</strong></p><p>如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果<strong>数据是随机插入的</strong>，就可能造成索引的数据页分裂。</p><p><img src="/../images/8083f05a4a4c0372833a6e01d5a8e6ea.png" alt="img"></p><p>可以看到，由于page A满了，再插入一个ID是550的数据时，就不得不再申请一个新的页面page B来保存数据了。页分裂完成后，page A的末尾就留下了空洞（注意：实际上，可能不止1个记录的位置是空洞）。</p><p>更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。</p><p>经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。</p><p><strong>重建表，就可以达到这样的目的。</strong></p><h4 id="重建表"><a href="#重建表" class="headerlink" title="重建表"></a>重建表</h4><p>你可以新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。</p><p>于表B是新建的表，所以表A主键索引上的空洞，在表B中就都不存在了。显然地，表B的主键索引更紧凑，数据页的利用率也更高。如果我们把表B作为临时表，数据从表A导入表B的操作完成后，用表B替换A，从效果上看，就起到了收缩表A空间的作用。</p><p>你可以使用alter table A engine&#x3D;InnoDB命令来重建表。在MySQL 5.5版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表B不需要你自己创建，MySQL会自动完成转存数据、交换表名、删除旧表的操作。</p><p><img src="/../images/02e083adaec6e1191f54992f7bc13dcd.png" alt="img"></p><p>显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表A的话，就会造成数据丢失。因此，在整个DDL过程中，表A中不能有更新。也就是说，这个DDL不是Online的。</p><p><strong>MySQL 5.6版本开始引入的Online DDL，对这个操作流程做了优化。</strong></p><ol><li>建立一个临时文件，扫描表A主键的所有数据页；</li><li>用数据页中表A的记录生成B+树，存储到临时文件中；</li><li>生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；</li><li>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；</li><li>用临时文件替换表A的数据文件。</li></ol><p><img src="/../images/2d1cfbbeb013b851a56390d38b5321f0.png" alt="img"></p><p>DDL之前是要拿MDL写锁的，这样还能叫Online DDL吗？</p><p>确实，图4的流程中，alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。</p><p>alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。</p><p>什么要退化呢？为了实现Online，MDL读锁不会阻塞增删改操作。</p><p>那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做DDL。</p><p>而对于一个大表来说，Online DDL最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个DDL过程来说，锁的时间非常短。对业务来说，就可以认为是Online的。</p><p>上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗IO和CPU资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用GitHub开源的<strong>gh-ost</strong>来做。</p><h4 id="Online-和-inplace"><a href="#Online-和-inplace" class="headerlink" title="Online 和 inplace"></a>Online 和 inplace</h4><p>我们把表A中的数据导出来的存放位置叫作tmp_table。这是一个临时表，是在server层创建的。</p><p>根据表A重建出来的数据是放在“tmp_file”里的，这个临时文件是InnoDB在内部创建出来的。整个DDL过程都在InnoDB内部完成。对于server层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。</p><p>所以，我现在问你，如果你有一个1TB的表，现在磁盘间是1.2TB，能不能做一个inplace的DDL呢？</p><p>答案是不能。因为，tmp_file也是要占用临时空间的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>标签</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
